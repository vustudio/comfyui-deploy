{
  "3": {
    "inputs": {
      "seed": 991658952683920,
      "steps": 7,
      "cfg": 1.3,
      "sampler_name": "lcm",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "14",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "10",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "ckpt_name": "turbovisionxlSuperFastXLBasedOnNew_tvxlV32Bakedvae.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "6": {
    "inputs": {
      "text": "a beautiful woman, red hair, hi detail, sharp focus, perfect lighting, awesome, dslr, 4k high quality. extra detail, extra sharp, magical, perfect moment, natural skin, film, film grain, flare, old film, discolored film, magazine paper, 35mm photo, grainy, vignette, vintage, Kodachrome, Lomography, f1.2 50m",
      "clip": [
        "14",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "(over exposed)long neck",
      "clip": [
        "14",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "4",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "10": {
    "inputs": {
      "resolution": "1472 x 704 (2.09)",
      "batch_size": 1
    },
    "class_type": "SDXL Empty Latent Image",
    "_meta": {
      "title": "SDXL Empty Latent Image"
    }
  },
  "14": {
    "inputs": {
      "lora_name": "LCM/SDXL/LCM_LoRA_Weights_SD15.safetensors",
      "strength_model": 1,
      "strength_clip": 1,
      "model": [
        "4",
        0
      ],
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "15": {
    "inputs": {
      "images": [
        "8",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  }
}